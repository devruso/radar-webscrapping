# ğŸ”— IntegraÃ§Ã£o com Radar-Infra

InstruÃ§Ãµes especÃ­ficas para integraÃ§Ã£o do **radar-webscrapping** com o repositÃ³rio **radar-infra**.

## ğŸ“‹ VisÃ£o Geral da IntegraÃ§Ã£o

O **radar-infra** Ã© o repositÃ³rio de orquestraÃ§Ã£o que contÃ©m:
- Docker Compose para todos os 4 componentes
- ConfiguraÃ§Ãµes de rede e volumes
- Scripts de deploy e manutenÃ§Ã£o
- ConfiguraÃ§Ãµes de ambiente unificadas

## ğŸ—ï¸ Estrutura Esperada no radar-infra

```
radar-infra/
â”œâ”€â”€ docker-compose.yml           # âœ… JÃ¡ configurado com radar-webscrapping
â”œâ”€â”€ .env.example                # Configure as variÃ¡veis necessÃ¡rias  
â”œâ”€â”€ .env                        # Copie e ajuste do .env.example
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ init-db/               # Scripts de inicializaÃ§Ã£o do MySQL
â”‚   â””â”€â”€ deploy.sh              # Deploy automatizado
â”œâ”€â”€ radar-webscrapping/         # ğŸ“ Este repositÃ³rio (submodule)
â”œâ”€â”€ radar-webapi/              # ğŸ“ Backend Spring Boot
â”œâ”€â”€ radar-webapp/              # ğŸ“ Frontend React
â””â”€â”€ README.md                  # InstruÃ§Ãµes do sistema completo
```

## ğŸ”§ Setup no radar-infra

### 1. Clonar como Submodule

No repositÃ³rio **radar-infra**:

```bash
# Adicionar como submodule
git submodule add <radar-webscrapping-repo-url> radar-webscrapping

# Atualizar submodules
git submodule update --init --recursive

# Commit da adiÃ§Ã£o
git add .gitmodules radar-webscrapping
git commit -m "feat: adicionar radar-webscrapping como submodule"
```

### 2. Configurar .env no radar-infra

Adicione estas variÃ¡veis ao `.env` do **radar-infra**:

```env
# =============================================================================
# RADAR WEBSCRAPPING - CONFIGURAÃ‡Ã•ES
# =============================================================================

# VersÃ£o da imagem Docker
WEBSCRAPPING_VERSION=latest

# Porta de exposiÃ§Ã£o
WEBSCRAPPING_PORT=8000

# ConfiguraÃ§Ãµes de integraÃ§Ã£o com radar-webapi
RADAR_API_KEY=your-secure-production-api-key-here

# Agendamento automÃ¡tico (cron expression)
# PadrÃ£o: Todo dia Ã s 2h da manhÃ£
SCRAPING_SCHEDULE=0 2 * * *

# NÃ­vel de log para scraping
SCRAPING_LOG_LEVEL=INFO

# URL para o frontend (opcional)
VITE_WEBSCRAPPING_URL=http://localhost:8000

# ConfiguraÃ§Ãµes especÃ­ficas de performance
SCRAPING_CONCURRENT_LIMIT=3
SCRAPING_BATCH_SIZE=10
SCRAPING_TIMEOUT=300
```

### 3. Verificar docker-compose.yml

O **docker-compose.yml** do **radar-infra** jÃ¡ deve conter:

```yaml
# Scrapers - Python FastAPI
radar-webscrapping:
  build: 
    context: ./radar-webscrapping
    dockerfile: Dockerfile
  image: radar/webscrapping:${WEBSCRAPPING_VERSION:-latest}
  container_name: radar-webscrapping
  restart: unless-stopped
  ports:
    - "${WEBSCRAPPING_PORT:-8000}:8000"
  environment:
    RADAR_API_URL: http://radar-webapi:8080
    RADAR_API_KEY: ${RADAR_API_KEY}
    SCRAPING_SCHEDULE: ${SCRAPING_SCHEDULE:-0 2 * * *}
    LOG_LEVEL: ${SCRAPING_LOG_LEVEL:-INFO}
  depends_on:
    radar-webapi:
      condition: service_healthy
  networks:
    - radar-network
  volumes:
    - scraping_data:/app/data
    - scraping_logs:/app/logs
```

## ğŸš€ Deploy Completo

### 1. PreparaÃ§Ã£o

```bash
# No diretÃ³rio radar-infra
cd radar-infra

# Atualizar submodules
git submodule update --remote --merge

# Verificar estrutura
ls -la
# Deve conter: radar-webscrapping, radar-webapi, radar-webapp
```

### 2. ConfiguraÃ§Ã£o

```bash
# Copiar configuraÃ§Ã£o exemplo
cp .env.example .env

# Editar configuraÃ§Ãµes
vim .env  # ou seu editor preferido

# Verificar configuraÃ§Ã£o do webscrapping
grep WEBSCRAPPING .env
```

### 3. Build e Deploy

```bash
# Build de todas as imagens
docker-compose build

# Deploy completo (primeira vez)
docker-compose up -d

# Verificar status
docker-compose ps
```

### 4. VerificaÃ§Ã£o

```bash
# Health check de todos os serviÃ§os
curl http://localhost:3306  # MySQL
curl http://localhost:8080/actuator/health  # WebAPI
curl http://localhost:8000/health           # WebScrapping  
curl http://localhost:3000                  # WebApp

# Logs do webscrapping
docker-compose logs -f radar-webscrapping
```

## ğŸ”„ Fluxo de Dados Integrado

### 1. Coleta (WebScrapping)
```
SIGAA UFBA â†’ radar-webscrapping â†’ Dados estruturados
```

### 2. Processamento (WebAPI)
```
radar-webscrapping â†’ radar-webapi â†’ MySQL
```

### 3. ApresentaÃ§Ã£o (WebApp)
```
MySQL â†’ radar-webapi â†’ radar-webapp â†’ UsuÃ¡rio
```

### 4. Agendamento
```
Cron (2h) â†’ radar-webscrapping â†’ Coleta automÃ¡tica
```

## ğŸ› ï¸ Comandos de ManutenÃ§Ã£o

### Atualizar WebScrapping

```bash
# No radar-infra
cd radar-webscrapping
git pull origin main
cd ..

# Rebuild e redeploy
docker-compose build radar-webscrapping
docker-compose up -d radar-webscrapping
```

### Logs e Monitoring

```bash
# Logs de todos os componentes
docker-compose logs -f

# Logs apenas do webscrapping
docker-compose logs -f radar-webscrapping

# Logs com filtro
docker-compose logs radar-webscrapping | grep ERROR

# Status detalhado
docker-compose ps
docker stats
```

### Backup de Dados

```bash
# Backup dos dados de scraping
docker run --rm \
  -v radar-infra_scraping_data:/data \
  -v $(pwd)/backups:/backup \
  ubuntu tar czf /backup/scraping-data-$(date +%Y%m%d).tar.gz -C /data .

# Backup dos logs
docker run --rm \
  -v radar-infra_scraping_logs:/logs \
  -v $(pwd)/backups:/backup \
  ubuntu tar czf /backup/scraping-logs-$(date +%Y%m%d).tar.gz -C /logs .
```

### ExecuÃ§Ã£o Manual de Scraping

```bash
# Scraping de cursos especÃ­fico
docker-compose exec radar-webscrapping python main.py scrape-cursos --unidade "IME"

# Scraping completo
docker-compose exec radar-webscrapping python main.py scrape-completo

# Status do sistema
docker-compose exec radar-webscrapping python main.py status
```

## ğŸ” Troubleshooting

### Problemas Comuns

#### 1. Container nÃ£o inicia
```bash
# Verificar logs
docker-compose logs radar-webscrapping

# Verificar dependÃªncias
docker-compose ps
# radar-webapi deve estar "healthy"

# Verificar rede
docker network ls | grep radar
```

#### 2. Erro de conexÃ£o com WebAPI
```bash
# Testar conectividade interna
docker-compose exec radar-webscrapping curl http://radar-webapi:8080/actuator/health

# Verificar variÃ¡veis de ambiente
docker-compose exec radar-webscrapping env | grep RADAR_API
```

#### 3. Scraping nÃ£o funciona
```bash
# Executar manualmente para debug
docker-compose exec radar-webscrapping python main.py scrape-cursos --debug

# Verificar Chrome/ChromeDriver
docker-compose exec radar-webscrapping google-chrome --version
docker-compose exec radar-webscrapping chromedriver --version
```

#### 4. Performance issues
```bash
# Verificar recursos
docker stats radar-webscrapping

# Ajustar limits no docker-compose.yml
```

### Debug AvanÃ§ado

```bash
# Shell no container
docker-compose exec radar-webscrapping bash

# Python REPL
docker-compose exec radar-webscrapping python

# Ver configuraÃ§Ãµes carregadas
docker-compose exec radar-webscrapping python -c "
from src.shared.config import Config
config = Config()
print(f'Database: {config.database_url}')
print(f'API URL: {config.radar_api_base_url}')
"
```

## ğŸ“Š Monitoramento em ProduÃ§Ã£o

### Health Checks

Todos os health checks estÃ£o configurados:

```bash
# WebScrapping
curl http://localhost:8000/health

# Verificar status no docker-compose
docker-compose ps
# STATUS deve ser "Up (healthy)"
```

### MÃ©tricas

```bash
# MÃ©tricas bÃ¡sicas
curl http://localhost:8000/metrics

# Status dos jobs
curl http://localhost:8000/api/jobs/status

# EstatÃ­sticas de scraping
curl http://localhost:8000/api/stats
```

### Alertas Recomendados

Configure alertas para:
- Container parado ou unhealthy
- Alto uso de memÃ³ria (>1GB)
- Falhas consecutivas de scraping
- Logs de ERROR
- Disk space dos volumes

## ğŸš€ Deploy em ProduÃ§Ã£o

### ConfiguraÃ§Ãµes de ProduÃ§Ã£o

```env
# .env para produÃ§Ã£o
APP_ENV=production
LOG_LEVEL=INFO
LOG_FORMAT=json

# Recursos limitados
SCRAPING_CONCURRENT_LIMIT=2
SCRAPING_TIMEOUT=180

# Security
RADAR_API_KEY=super-secure-production-key

# Performance
SELENIUM_HEADLESS=true
DATABASE_POOL_SIZE=10
```

### CI/CD Integration

```yaml
# .github/workflows/deploy.yml (exemplo)
name: Deploy Radar Infra
on:
  push:
    branches: [main]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
        with:
          submodules: recursive
      
      - name: Deploy to production
        run: |
          docker-compose -f docker-compose.prod.yml up -d
          docker-compose ps
```

## ğŸ“ Checklist de IntegraÃ§Ã£o

- [ ] radar-webscrapping adicionado como submodule
- [ ] .env configurado com variÃ¡veis do webscrapping
- [ ] docker-compose.yml contÃ©m configuraÃ§Ã£o do radar-webscrapping
- [ ] Build funciona: `docker-compose build radar-webscrapping`
- [ ] Deploy funciona: `docker-compose up -d`
- [ ] Health check passa: `curl http://localhost:8000/health`
- [ ] IntegraÃ§Ã£o com WebAPI funciona
- [ ] Logs aparecem: `docker-compose logs radar-webscrapping`
- [ ] Volumes persistem dados em `/app/data` e `/app/logs`
- [ ] Rede permite comunicaÃ§Ã£o entre serviÃ§os

---

**Sistema Radar - IntegraÃ§Ã£o Completa** ğŸ¯  
**Todos os 4 componentes funcionando em harmonia** âš™ï¸