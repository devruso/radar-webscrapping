# üîÑ Fluxo de Desenvolvimento Di√°rio

**Guia pr√°tico para trabalhar no radar-webscrapping no dia a dia**

## üåÖ Come√ßando o Dia de Trabalho

### 1. **Setup Inicial (primeira vez no dia)**

```bash
# Navegue at√© o projeto
cd c:\Users\jamil\Documents\programming\radar-webscrapping

# Atualize o c√≥digo
git pull origin main

# Suba o ambiente Docker
docker-compose up -d

# Verifique se tudo subiu
docker-compose ps
```

**O que voc√™ ver√° se tudo estiver OK:**
```
Name                     State       Ports
webscrapping             Up          0.0.0.0:8000->8000/tcp
postgres                 Up          5432/tcp
redis                    Up          6379/tcp
```

### 2. **Verifica√ß√£o R√°pida do Sistema**

```bash
# Teste b√°sico - aplica√ß√£o responde?
docker-compose exec webscrapping python main.py status

# Teste scraping simples
docker-compose exec webscrapping python main.py scrape-cursos --help
```

---

## üõ†Ô∏è Desenvolvendo uma Nova Feature

### Cen√°rio: "Preciso modificar como o scraper coleta dados de componentes curriculares"

#### Passo 1: Entender o C√≥digo Atual

```bash
# Ver estrutura dos scrapers
ls src/scrapers/

# Ler c√≥digo atual (exemplo)
cat src/scrapers/componente_scraper.py
```

#### Passo 2: Criar Branch para Trabalhar

```bash
# Criar branch descritiva
git checkout -b feature/melhorar-coleta-componentes

# Verificar que est√° na branch certa
git branch
```

#### Passo 3: Fazer Altera√ß√µes

**Exemplo pr√°tico - Modificar URL de coleta:**

```python
# Em src/scrapers/componente_scraper.py

class ComponenteScraper:
    def __init__(self):
        # ANTES:
        self.base_url = "https://sigaa.ufba.br/sigaa/geral/componente_curricular/busca_geral.jsf"
        
        # DEPOIS (sua altera√ß√£o):
        self.base_url = "https://sigaa.ufba.br/sigaa/graduacao/componente_curricular/lista.jsf"
        
    def coletar_componentes(self):
        # Sua l√≥gica aqui
        pass
```

#### Passo 4: Testar Altera√ß√£o Localmente

```bash
# Teste espec√≠fico da sua altera√ß√£o
docker-compose exec webscrapping python -c "
from src.scrapers.componente_scraper import ComponenteScraper
scraper = ComponenteScraper()
print('URL configurada:', scraper.base_url)
"

# Teste funcional
docker-compose exec webscrapping python main.py scrape-componentes --codigo "MAT001"
```

#### Passo 5: Executar Testes Completos

```bash
# Testes relacionados aos componentes
docker-compose exec webscrapping pytest tests/ -k "componente" -v

# Se criou novos testes, execute todos
docker-compose exec webscrapping pytest tests/ -v
```

#### Passo 6: Commit das Altera√ß√µes

```bash
# Verificar o que mudou
git status
git diff

# Adicionar arquivos modificados
git add src/scrapers/componente_scraper.py

# Se criou testes
git add tests/test_componente_scraper.py

# Commit com mensagem descritiva
git commit -m "feat: atualizar URL de coleta de componentes curriculares

- Mudan√ßa da URL de busca geral para lista espec√≠fica
- Melhora na precis√£o dos dados coletados
- Testes atualizados para nova URL"

# Push da branch
git push origin feature/melhorar-coleta-componentes
```

#### Passo 7: Pull Request e Testes Autom√°ticos

```bash
# No GitHub:
# 1. V√° para seu reposit√≥rio
# 2. GitHub mostrar√° "Compare & pull request"
# 3. Clique e descreva suas mudan√ßas
# 4. Create pull request
```

**GitHub Actions automaticamente:**
- ‚úÖ Roda todos os testes
- ‚úÖ Verifica qualidade do c√≥digo
- ‚úÖ Faz build Docker
- ‚úÖ Verifica seguran√ßa

#### Passo 8: Merge (s√≥ se tudo passou)

```bash
# Se CI passou:
# ‚Üí GitHub: Merge pull request

# Limpar localmente:
git checkout main
git pull origin main
git branch -d feature/melhorar-coleta-componentes
```

---

## üêõ Debuggando Problemas

### Cen√°rio: "Scraper n√£o est√° coletando dados"

#### Debug Passo a Passo:

#### 1. **Verificar Logs B√°sicos**

```bash
# Ver logs recentes
docker-compose logs --tail=50 webscrapping

# Logs em tempo real
docker-compose logs -f webscrapping
```

#### 2. **Entrar no Container para Debug Manual**

```bash
# Abrir bash no container
docker-compose exec webscrapping bash

# Voc√™ agora est√° dentro do container
# Teste Python interativo
python
```

#### 3. **Debug Interativo**

```python
# No Python dentro do container:

# Testar imports
>>> from src.scrapers.curso_scraper import CursoScraper
>>> from selenium import webdriver
>>> from selenium.webdriver.chrome.options import Options

# Configurar Chrome para ver o que est√° acontecendo
>>> options = Options()
>>> options.add_argument('--no-sandbox')
>>> options.add_argument('--disable-dev-shm-usage')
>>> # Para debug visual, remova headless:
>>> # options.add_argument('--headless=false')

>>> driver = webdriver.Chrome(options=options)

# Testar conex√£o com SIGAA
>>> driver.get('https://sigaa.ufba.br')
>>> print("T√≠tulo da p√°gina:", driver.title)
>>> print("URL atual:", driver.current_url)

# Se chegou at√© aqui, Selenium funciona
# Agora teste seu scraper
>>> scraper = CursoScraper()
>>> # Teste m√©todos individuais
>>> driver.quit()
>>> exit()
```

#### 4. **Debug de URL Espec√≠fica**

```python
# Teste se uma URL espec√≠fica funciona
>>> import requests
>>> response = requests.get('https://sigaa.ufba.br/sigaa/geral/curso/busca_geral.jsf')
>>> print("Status:", response.status_code)
>>> print("Conte√∫do (primeiros 200 chars):", response.text[:200])
```

#### 5. **Testar Scraper com Debug Detalhado**

```bash
# Voltar ao bash do container
exit  # sair do Python

# Executar com debug m√°ximo
export LOG_LEVEL=DEBUG
python main.py scrape-cursos --unidade "IME" --debug

# Ver arquivos de log
ls logs/
tail -f logs/scraping.log
```

---

## üß™ Testando Suas Altera√ß√µes

### Tipos de Teste Durante Desenvolvimento:

#### 1. **Teste R√°pido (Smoke Test)**

```bash
# Teste se b√°sico funciona (30 segundos)
docker-compose exec webscrapping python -c "
from src.scrapers import CursoScraper
scraper = CursoScraper()
print('‚úÖ Import OK')
"
```

#### 2. **Teste Funcional Espec√≠fico**

```bash
# Teste uma fun√ß√£o espec√≠fica
docker-compose exec webscrapping python -c "
from src.scrapers.curso_scraper import CursoScraper
scraper = CursoScraper()
cursos = scraper.buscar_cursos_por_unidade('IME')
print(f'‚úÖ Encontrados {len(cursos)} cursos')
"
```

#### 3. **Teste de Integra√ß√£o**

```bash
# Teste completo end-to-end
docker-compose exec webscrapping python main.py scrape-cursos --unidade "IME" --limit 5
```

#### 4. **Testes Unit√°rios**

```bash
# Executar testes espec√≠ficos
docker-compose exec webscrapping pytest tests/test_curso_scraper.py -v

# Teste com coverage
docker-compose exec webscrapping pytest tests/ --cov=src --cov-report=term-missing
```

#### 5. **Teste de Performance**

```bash
# Medir tempo de execu√ß√£o
docker-compose exec webscrapping python -c "
import time
from src.scrapers.curso_scraper import CursoScraper

start = time.time()
scraper = CursoScraper()
cursos = scraper.buscar_cursos_por_unidade('IME')
end = time.time()

print(f'‚è±Ô∏è Tempo: {end-start:.2f}s')
print(f'üìä Cursos/segundo: {len(cursos)/(end-start):.2f}')
"
```

---

## üîÑ Workflow para Diferentes Tipos de Mudan√ßa

### 1. **Bug Fix Simples (m√©todo r√°pido)**

```bash
# Para corre√ß√µes pequenas, trabalhe direto na main
git pull origin main

# Fa√ßa a corre√ß√£o
# ... edite arquivos ...

# Teste r√°pido
docker-compose exec webscrapping python main.py status

# Commit e push
git add .
git commit -m "fix: corrigir typo na URL do SIGAA"
git push origin main

# GitHub Actions testa automaticamente
```

### 2. **Nova Feature (m√©todo seguro)**

```bash
# Sempre usar branch
git checkout -b feature/nova-funcionalidade

# Desenvolver
# ... suas altera√ß√µes ...

# Testar localmente
pytest tests/

# Push da branch
git push origin feature/nova-funcionalidade

# Pull Request no GitHub
# Merge s√≥ depois que CI passar
```

### 3. **Refatora√ß√£o Grande**

```bash
# Branch espec√≠fica
git checkout -b refactor/reorganizar-scrapers

# Trabalhar em etapas pequenas
# Commit frequentemente
git add .
git commit -m "refactor: mover classe base para m√≥dulo separado"

# Continuar...
git add .
git commit -m "refactor: atualizar imports ap√≥s reorganiza√ß√£o"

# Push da branch
git push origin refactor/reorganizar-scrapers

# Pull Request com descri√ß√£o detalhada
```

---

## üìä Monitorando Qualidade do C√≥digo

### Durante Desenvolvimento:

#### 1. **Qualidade de C√≥digo (Linting)**

```bash
# Verificar estilo do c√≥digo
docker-compose exec webscrapping flake8 src/

# Formata√ß√£o autom√°tica
docker-compose exec webscrapping black src/

# Verificar tipos
docker-compose exec webscrapping mypy src/
```

#### 2. **Cobertura de Testes**

```bash
# Ver cobertura atual
docker-compose exec webscrapping pytest tests/ --cov=src --cov-report=html

# Abrir relat√≥rio HTML (fora do container)
# Vai criar htmlcov/index.html
# Abra no navegador para ver detalhes
```

#### 3. **An√°lise de Seguran√ßa**

```bash
# Verificar vulnerabilidades em depend√™ncias
docker-compose exec webscrapping safety check

# An√°lise de c√≥digo
docker-compose exec webscrapping bandit -r src/
```

---

## üöÄ Preparando para Deploy

### Antes de Fazer Release:

#### 1. **Teste Local Completo**

```bash
# Executar todos os testes
docker-compose exec webscrapping pytest tests/ -v

# Teste de build
docker build -t radar/webscrapping:test .

# Teste do container build
docker run --rm radar/webscrapping:test cli --help
```

#### 2. **Verificar Documenta√ß√£o**

```bash
# README.md atualizado?
# CHANGELOG.md atualizado?
# Vers√£o no requirements.txt?
```

#### 3. **Create Release Tag**

```bash
# Certifique-se que est√° na main
git checkout main
git pull origin main

# Criar tag de vers√£o
git tag v1.0.0
git push origin v1.0.0

# GitHub Actions automaticamente:
# - Faz build de produ√ß√£o
# - Cria release no GitHub
# - Publica Docker image
```

---

## üéØ Comandos de Emerg√™ncia

### "Algo deu muito errado!"

#### 1. **Reset Completo do Ambiente**

```bash
# Parar tudo
docker-compose down -v

# Limpar containers
docker system prune -f

# Remover imagens
docker rmi radar/webscrapping

# Reconstruir do zero
docker-compose build --no-cache
docker-compose up -d
```

#### 2. **Voltar para √öltima Vers√£o que Funcionava**

```bash
# Ver commits recentes
git log --oneline -10

# Voltar para commit espec√≠fico
git reset --hard [hash-do-commit]

# For√ßa push (CUIDADO!)
git push origin main --force
```

#### 3. **Backup dos Dados**

```bash
# Backup do banco local
docker-compose exec postgres pg_dump -U postgres radar_webscrapping > backup.sql

# Backup de logs
docker-compose exec webscrapping tar czf /tmp/logs-backup.tar.gz logs/
docker cp webscrapping_container:/tmp/logs-backup.tar.gz ./
```

---

## üìà M√©tricas de Qualidade

### Acompanhe Estes Indicadores:

#### 1. **Build Time**
- GitHub Actions deve completar em < 20 minutos
- Se est√° demorando mais, otimize

#### 2. **Test Coverage**
- Objetivo: > 80%
- Comando: `pytest tests/ --cov=src`

#### 3. **Code Quality**
- Sem erros de flake8
- Sem warnings de mypy

#### 4. **Performance de Scraping**
- Cursos: < 30 segundos para uma unidade
- Componentes: < 60 segundos para um curso

---

## üìù Checklist Di√°rio

### Antes de Come√ßar:
- [ ] `git pull origin main`
- [ ] `docker-compose up -d`
- [ ] `docker-compose ps` (tudo UP?)

### Durante Desenvolvimento:
- [ ] Trabalhar em branch para features
- [ ] Testar localmente antes de commit
- [ ] Commits pequenos e frequentes
- [ ] Mensagens de commit descritivas

### Antes de Finalizar:
- [ ] `pytest tests/` (todos passam?)
- [ ] `git status` (tudo commitado?)
- [ ] Push da branch
- [ ] CI passou no GitHub?

### Limpeza:
- [ ] Merge da branch
- [ ] Delete branch local
- [ ] `docker-compose down` (se n√£o vai usar)

---

**üéâ Com este fluxo, voc√™ desenvolve com seguran√ßa e qualidade!**

**Lembre-se:**
- ‚úÖ Docker simplifica o ambiente
- ‚úÖ GitHub Actions previne bugs em produ√ß√£o
- ‚úÖ Branches protegem c√≥digo principal
- ‚úÖ Testes garantem qualidade
- ‚úÖ Logs ajudam no debug

**Bom desenvolvimento! üöÄ**