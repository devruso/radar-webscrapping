# ðŸ”„ Fluxo de Desenvolvimento DiÃ¡rio

**Guia prÃ¡tico para trabalhar no radar-webscrapping no dia a dia**

## ðŸŒ… ComeÃ§ando o Dia de Trabalho

### 1. **Setup Inicial (primeira vez no dia)**

```bash
# Navegue atÃ© o projeto
cd c:\Users\jamil\Documents\programming\radar-webscrapping

# Atualize o cÃ³digo
git pull origin main

# Suba o ambiente Docker
docker-compose up -d

# Verifique se tudo subiu
docker-compose ps
```

**O que vocÃª verÃ¡ se tudo estiver OK:**
```
Name                     State       Ports
webscrapping             Up          0.0.0.0:8000->8000/tcp
postgres                 Up          5432/tcp
redis                    Up          6379/tcp
```

### 2. **VerificaÃ§Ã£o RÃ¡pida do Sistema**

```bash
# Teste bÃ¡sico - aplicaÃ§Ã£o responde?
docker-compose exec webscrapping python main.py status

# Teste scraping simples
docker-compose exec webscrapping python main.py scrape-cursos --help
```

---

## ðŸ› ï¸ Desenvolvendo uma Nova Feature

### CenÃ¡rio: "Preciso modificar como o scraper coleta dados de componentes curriculares"

#### Passo 1: Entender o CÃ³digo Atual

```bash
# Ver estrutura dos scrapers
ls src/scrapers/

# Ler cÃ³digo atual (exemplo)
cat src/scrapers/componente_scraper.py
```

#### Passo 2: Criar Branch para Trabalhar

```bash
# Criar branch descritiva
git checkout -b feature/melhorar-coleta-componentes

# Verificar que estÃ¡ na branch certa
git branch
```

#### Passo 3: Fazer AlteraÃ§Ãµes

**Exemplo prÃ¡tico - Modificar URL de coleta:**

```python
# Em src/scrapers/componente_scraper.py

class ComponenteScraper:
    def __init__(self):
        # ANTES:
        self.base_url = "https://sigaa.ufba.br/sigaa/geral/componente_curricular/busca_geral.jsf"
        
        # DEPOIS (sua alteraÃ§Ã£o):
        self.base_url = "https://sigaa.ufba.br/sigaa/graduacao/componente_curricular/lista.jsf"
        
    def coletar_componentes(self):
        # Sua lÃ³gica aqui
        pass
```

#### Passo 4: Testar AlteraÃ§Ã£o Localmente

```bash
# Teste especÃ­fico da sua alteraÃ§Ã£o
docker-compose exec webscrapping python -c "
from src.scrapers.componente_scraper import ComponenteScraper
scraper = ComponenteScraper()
print('URL configurada:', scraper.base_url)
"

# Teste funcional
docker-compose exec webscrapping python main.py scrape-componentes --codigo "MAT001"
```

#### Passo 5: Executar Testes Completos

```bash
# Testes relacionados aos componentes
docker-compose exec webscrapping pytest tests/ -k "componente" -v

# Se criou novos testes, execute todos
docker-compose exec webscrapping pytest tests/ -v
```

#### Passo 6: Commit das AlteraÃ§Ãµes

```bash
# Verificar o que mudou
git status
git diff

# Adicionar arquivos modificados
git add src/scrapers/componente_scraper.py

# Se criou testes
git add tests/test_componente_scraper.py

# Commit com mensagem descritiva
git commit -m "feat: atualizar URL de coleta de componentes curriculares

- MudanÃ§a da URL de busca geral para lista especÃ­fica
- Melhora na precisÃ£o dos dados coletados
- Testes atualizados para nova URL"

# Push da branch
git push origin feature/melhorar-coleta-componentes
```

#### Passo 7: Pull Request e Testes AutomÃ¡ticos

```bash
# No GitHub:
# 1. VÃ¡ para seu repositÃ³rio
# 2. GitHub mostrarÃ¡ "Compare & pull request"
# 3. Clique e descreva suas mudanÃ§as
# 4. Create pull request
```

**GitHub Actions automaticamente:**
- âœ… Roda todos os testes
- âœ… Verifica qualidade do cÃ³digo
- âœ… Faz build Docker
- âœ… Verifica seguranÃ§a

#### Passo 8: Merge (sÃ³ se tudo passou)

```bash
# Se CI passou:
# â†’ GitHub: Merge pull request

# Limpar localmente:
git checkout main
git pull origin main
git branch -d feature/melhorar-coleta-componentes
```

---

## ðŸ› Debuggando Problemas

### CenÃ¡rio: "Scraper nÃ£o estÃ¡ coletando dados"

#### Debug Passo a Passo:

#### 1. **Verificar Logs BÃ¡sicos**

```bash
# Ver logs recentes
docker-compose logs --tail=50 webscrapping

# Logs em tempo real
docker-compose logs -f webscrapping
```

#### 2. **Entrar no Container para Debug Manual**

```bash
# Abrir bash no container
docker-compose exec webscrapping bash

# VocÃª agora estÃ¡ dentro do container
# Teste Python interativo
python
```

#### 3. **Debug Interativo**

```python
# No Python dentro do container:

# Testar imports
>>> from src.scrapers.curso_scraper import CursoScraper
>>> from selenium import webdriver
>>> from selenium.webdriver.chrome.options import Options

# Configurar Chrome para ver o que estÃ¡ acontecendo
>>> options = Options()
>>> options.add_argument('--no-sandbox')
>>> options.add_argument('--disable-dev-shm-usage')
>>> # Para debug visual, remova headless:
>>> # options.add_argument('--headless=false')

>>> driver = webdriver.Chrome(options=options)

# Testar conexÃ£o com SIGAA
>>> driver.get('https://sigaa.ufba.br')
>>> print("TÃ­tulo da pÃ¡gina:", driver.title)
>>> print("URL atual:", driver.current_url)

# Se chegou atÃ© aqui, Selenium funciona
# Agora teste seu scraper
>>> scraper = CursoScraper()
>>> # Teste mÃ©todos individuais
>>> driver.quit()
>>> exit()
```

#### 4. **Debug de URL EspecÃ­fica**

```python
# Teste se uma URL especÃ­fica funciona
>>> import requests
>>> response = requests.get('https://sigaa.ufba.br/sigaa/geral/curso/busca_geral.jsf')
>>> print("Status:", response.status_code)
>>> print("ConteÃºdo (primeiros 200 chars):", response.text[:200])
```

#### 5. **Testar Scraper com Debug Detalhado**

```bash
# Voltar ao bash do container
exit  # sair do Python

# Executar com debug mÃ¡ximo
export LOG_LEVEL=DEBUG
python main.py scrape-cursos --unidade "IME" --debug

# Ver arquivos de log
ls logs/
tail -f logs/scraping.log
```

---

## ðŸ§ª Testando Suas AlteraÃ§Ãµes

### Tipos de Teste Durante Desenvolvimento:

#### 1. **Teste RÃ¡pido (Smoke Test)**

```bash
# Teste se bÃ¡sico funciona (30 segundos)
docker-compose exec webscrapping python -c "
from src.scrapers import CursoScraper
scraper = CursoScraper()
print('âœ… Import OK')
"
```

#### 2. **Teste Funcional EspecÃ­fico**

```bash
# Teste uma funÃ§Ã£o especÃ­fica
docker-compose exec webscrapping python -c "
from src.scrapers.curso_scraper import CursoScraper
scraper = CursoScraper()
cursos = scraper.buscar_cursos_por_unidade('IME')
print(f'âœ… Encontrados {len(cursos)} cursos')
"
```

#### 3. **Teste de IntegraÃ§Ã£o**

```bash
# Teste completo end-to-end
docker-compose exec webscrapping python main.py scrape-cursos --unidade "IME" --limit 5
```

#### 4. **Testes UnitÃ¡rios**

```bash
# Executar testes especÃ­ficos
docker-compose exec webscrapping pytest tests/test_curso_scraper.py -v

# Teste com coverage
docker-compose exec webscrapping pytest tests/ --cov=src --cov-report=term-missing
```

#### 5. **Teste de Performance**

```bash
# Medir tempo de execuÃ§Ã£o
docker-compose exec webscrapping python -c "
import time
from src.scrapers.curso_scraper import CursoScraper

start = time.time()
scraper = CursoScraper()
cursos = scraper.buscar_cursos_por_unidade('IME')
end = time.time()

print(f'â±ï¸ Tempo: {end-start:.2f}s')
print(f'ðŸ“Š Cursos/segundo: {len(cursos)/(end-start):.2f}')
"
```

---

## ðŸ”„ Workflow para Diferentes Tipos de MudanÃ§a

### 1. **Bug Fix Simples (mÃ©todo rÃ¡pido)**

```bash
# Para correÃ§Ãµes pequenas, trabalhe direto na main
git pull origin main

# FaÃ§a a correÃ§Ã£o
# ... edite arquivos ...

# Teste rÃ¡pido
docker-compose exec webscrapping python main.py status

# Commit e push
git add .
git commit -m "fix: corrigir typo na URL do SIGAA"
git push origin main

# GitHub Actions testa automaticamente
```

### 2. **Nova Feature (mÃ©todo seguro)**

```bash
# Sempre usar branch
git checkout -b feature/nova-funcionalidade

# Desenvolver
# ... suas alteraÃ§Ãµes ...

# Testar localmente
pytest tests/

# Push da branch
git push origin feature/nova-funcionalidade

# Pull Request no GitHub
# Merge sÃ³ depois que CI passar
```

### 3. **RefatoraÃ§Ã£o Grande**

```bash
# Branch especÃ­fica
git checkout -b refactor/reorganizar-scrapers

# Trabalhar em etapas pequenas
# Commit frequentemente
git add .
git commit -m "refactor: mover classe base para mÃ³dulo separado"

# Continuar...
git add .
git commit -m "refactor: atualizar imports apÃ³s reorganizaÃ§Ã£o"

# Push da branch
git push origin refactor/reorganizar-scrapers

# Pull Request com descriÃ§Ã£o detalhada
```

---

## ðŸ“Š Monitorando Qualidade do CÃ³digo

### Durante Desenvolvimento:

#### 1. **Qualidade de CÃ³digo (Linting)**

```bash
# Verificar estilo do cÃ³digo
docker-compose exec webscrapping flake8 src/

# FormataÃ§Ã£o automÃ¡tica
docker-compose exec webscrapping black src/

# Verificar tipos
docker-compose exec webscrapping mypy src/
```

#### 2. **Cobertura de Testes**

```bash
# Ver cobertura atual
docker-compose exec webscrapping pytest tests/ --cov=src --cov-report=html

# Abrir relatÃ³rio HTML (fora do container)
# Vai criar htmlcov/index.html
# Abra no navegador para ver detalhes
```

#### 3. **AnÃ¡lise de SeguranÃ§a**

```bash
# Verificar vulnerabilidades em dependÃªncias
docker-compose exec webscrapping safety check

# AnÃ¡lise de cÃ³digo
docker-compose exec webscrapping bandit -r src/
```

---

## ðŸš€ Preparando para Deploy

### Antes de Fazer Release:

#### 1. **Teste Local Completo**

```bash
# Executar todos os testes
docker-compose exec webscrapping pytest tests/ -v

# Teste de build
docker build -t radar/webscrapping:test .

# Teste do container build
docker run --rm radar/webscrapping:test cli --help
```

#### 2. **Verificar DocumentaÃ§Ã£o**

```bash
# README.md atualizado?
# CHANGELOG.md atualizado?
# VersÃ£o no requirements.txt?
```

#### 3. **Create Release Tag**

```bash
# Certifique-se que estÃ¡ na main
git checkout main
git pull origin main

# Criar tag de versÃ£o
git tag v1.0.0
git push origin v1.0.0

# GitHub Actions automaticamente:
# - Faz build de produÃ§Ã£o
# - Cria release no GitHub
# - Publica Docker image
```

---

## ðŸŽ¯ Comandos de EmergÃªncia

### "Algo deu muito errado!"

#### 1. **Reset Completo do Ambiente**

```bash
# Parar tudo
docker-compose down -v

# Limpar containers
docker system prune -f

# Remover imagens
docker rmi radar/webscrapping

# Reconstruir do zero
docker-compose build --no-cache
docker-compose up -d
```

#### 2. **Voltar para Ãšltima VersÃ£o que Funcionava**

```bash
# Ver commits recentes
git log --oneline -10

# Voltar para commit especÃ­fico
git reset --hard [hash-do-commit]

# ForÃ§a push (CUIDADO!)
git push origin main --force
```

#### 3. **Backup dos Dados**

```bash
# Backup do banco local
docker-compose exec postgres pg_dump -U postgres radar_webscrapping > backup.sql

# Backup de logs
docker-compose exec webscrapping tar czf /tmp/logs-backup.tar.gz logs/
docker cp webscrapping_container:/tmp/logs-backup.tar.gz ./
```

---

## ðŸ“ˆ MÃ©tricas de Qualidade

### Acompanhe Estes Indicadores:

#### 1. **Build Time**
- GitHub Actions deve completar em < 20 minutos
- Se estÃ¡ demorando mais, otimize

#### 2. **Test Coverage**
- Objetivo: > 80%
- Comando: `pytest tests/ --cov=src`

#### 3. **Code Quality**
- Sem erros de flake8
- Sem warnings de mypy

#### 4. **Performance de Scraping**
- Cursos: < 30 segundos para uma unidade
- Componentes: < 60 segundos para um curso

---

## ðŸ“ Checklist DiÃ¡rio

### Antes de ComeÃ§ar:
- [ ] `git pull origin main`
- [ ] `docker-compose up -d`
- [ ] `docker-compose ps` (tudo UP?)

### Durante Desenvolvimento:
- [ ] Trabalhar em branch para features
- [ ] Testar localmente antes de commit
- [ ] Commits pequenos e frequentes
- [ ] Mensagens de commit descritivas

### Antes de Finalizar:
- [ ] `pytest tests/` (todos passam?)
- [ ] `git status` (tudo commitado?)
- [ ] Push da branch
- [ ] CI passou no GitHub?

### Limpeza:
- [ ] Merge da branch
- [ ] Delete branch local
- [ ] `docker-compose down` (se nÃ£o vai usar)

---

**ðŸŽ‰ Com este fluxo, vocÃª desenvolve com seguranÃ§a e qualidade!**

**Lembre-se:**
- âœ… Docker simplifica o ambiente
- âœ… GitHub Actions previne bugs em produÃ§Ã£o
- âœ… Branches protegem cÃ³digo principal
- âœ… Testes garantem qualidade
- âœ… Logs ajudam no debug

**Bom desenvolvimento! ðŸš€**